{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import scipy.stats as stats\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, Column, MaskedColumn, join\n",
    "from tqdm import tqdm\n",
    "from bisect import bisect_left\n",
    "c = 2.998e10\n",
    "k = 1.38e-16\n",
    "h = 6.626e-27\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "halpha = 6564.61\n",
    "hbeta = 4862.68\n",
    "hgamma = 4341.68\n",
    "hdelta = 4102.89\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "from IPython.display import Audio, display\n",
    "def allDone():\n",
    "    display(Audio(filename='beep.mp3', autoplay=True))\n",
    "from scipy.interpolate import interp1d,InterpolatedUnivariateSpline\n",
    "import lmfit\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "import emcee\n",
    "import corner\n",
    "import numdifftools\n",
    "from scipy.ndimage import interpolation\n",
    "from scipy.signal import medfilt\n",
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import h5py\n",
    "import scipy\n",
    "from matplotlib.pyplot import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum(source_id):\n",
    "    path = wdtable[wdtable['source_id'] == source_id][0]['specpath']\n",
    "    try:\n",
    "        f = fits.open(path)\n",
    "        flux = f[1].data['flux']\n",
    "        loglam = f[1].data['loglam']\n",
    "        f.close()\n",
    "        lam = 10**loglam\n",
    "    except:\n",
    "        print('Spectrum file missing...')\n",
    "        return\n",
    "    return lam,flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5396\n",
      "5366\n"
     ]
    }
   ],
   "source": [
    "filetable = Table.read('filetable.fits')\n",
    "wdtable = Table.read('tremblay_final.fits')\n",
    "print(len(wdtable))\n",
    "wdtable = join(filetable,wdtable,keys = ['source_id'])\n",
    "\n",
    "DA = (wdtable['spectral_class_1'] == 'DA')\n",
    "wdtable = wdtable[DA]\n",
    "print(len(wdtable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wdtools.parametric import LineProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Line Profiles Tool for White Dwarf Spectra ### \n",
      "\n",
      "Verbose: False, plot_profiles: False\n",
      "\n",
      "\tGeneral class to fit Voigt profiles to the first 3 Balmer absorption lines, and then infer stellar labels.\n",
      "\tUses a 25-tree random forest model by default, trained on 5326 spectra from the Sloan Digital Sky Survey. \n",
      "\tProbabilistic prediction uses 100 boostrapped random forest models with 10 trees each, also SDSS-trained. \n",
      "\tGround truth labels are taken from Tremblay et al. (2019)\n",
      "\tLine profiles are fit using the LMFIT package via chi^2 minimization. \n",
      "\n",
      "\tTo get started, use LineProfiles.infer_labels(wavelength, flux)\n",
      "\tFor more details, run help(LineProfiles)\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2288/5366 [21:33<22:15,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile fit failed! returning NaN...\n",
      "profile fit failed! returning NaN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 3122/5366 [29:35<21:23,  1.75it/s]ZeroDivisionError\n",
      "   <_ast.Module object at 0x12f0eeb00>\n",
      "                                        ^^^\n",
      "complex division by zero\n",
      " 58%|█████▊    | 3123/5366 [29:35<18:53,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile fit failed! returning NaN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5366/5366 [50:53<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters = [];\n",
    "\n",
    "for i in tqdm(range(len(wdtable))):\n",
    "    spec = get_spectrum(wdtable['source_id'][i])\n",
    "    lam  = spec[0]\n",
    "    flux = spec[1]\n",
    "    balmer_params = lp.fit_balmer(lam,flux)\n",
    "    parameters.append(balmer_params)\n",
    "parameters = np.asarray(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nanmask = ~np.max(np.isnan(parameters),1)\n",
    "\n",
    "cleanparams = parameters[nanmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = ['sigma_a','center_a','amplitude_a','gamma_a','fwhm_a','height_a','sigma_b','center_b','amplitude_b','gamma_b','fwhm_b','height_b','sigma_g','center_g','amplitude_g','gamma_g','fwhm_g','height_g']\n",
    "df = pd.DataFrame(cleanparams, columns = names)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv('balmerparams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = (\n",
    "    (df['center_a'] < halpha + 25)&\n",
    "    (df['center_a'] > halpha - 25)&\n",
    "    (df['center_b'] < hbeta + 25)&\n",
    "    (df['center_b'] > hbeta - 25)&\n",
    "    (df['center_g'] < hgamma + 25)&\n",
    "    (df['center_g'] > hgamma - 25)&\n",
    "    (df['fwhm_a'] < 100)&\n",
    "    (df['fwhm_b'] < 100)&\n",
    "    (df['fwhm_g'] < 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df[clean]\n",
    "cleantable = wdtable[nanmask][np.asarray(clean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantable.write('balmerparamstable.fits', overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5363\n",
      "5130\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(dfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfc.to_numpy()\n",
    "t = np.asarray([cleantable['spec_Teff'], cleantable['spec_logg']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from wdtools.neural import BaseNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_input=15, n_output=2, n_hidden=2, neurons=10, activation='relu', output_activation='linear', regularization=0, loss='mse', bayesian=False, dropout=0.1)\n"
     ]
    }
   ],
   "source": [
    "bnn = BaseNN(n_input = len(X[0]), n_output = 2, n_hidden = 2, neurons = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5130/5130 [==============================] - 0s 29us/step - loss: 169881170.7867\n",
      "Epoch 2/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 40188473.8109\n",
      "Epoch 3/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34837289.0417\n",
      "Epoch 4/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34823631.4090\n",
      "Epoch 5/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34829061.1634\n",
      "Epoch 6/500\n",
      "5130/5130 [==============================] - 0s 12us/step - loss: 34790159.7965\n",
      "Epoch 7/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34761894.0881\n",
      "Epoch 8/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34735393.7326\n",
      "Epoch 9/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34754500.4600\n",
      "Epoch 10/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34685625.6920\n",
      "Epoch 11/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34670597.9634\n",
      "Epoch 12/500\n",
      "5130/5130 [==============================] - 0s 12us/step - loss: 34624461.5267\n",
      "Epoch 13/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34616490.5037\n",
      "Epoch 14/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34564753.5602\n",
      "Epoch 15/500\n",
      "5130/5130 [==============================] - 0s 12us/step - loss: 34509610.5715\n",
      "Epoch 16/500\n",
      "5130/5130 [==============================] - 0s 16us/step - loss: 34553652.3478\n",
      "Epoch 17/500\n",
      "5130/5130 [==============================] - 0s 14us/step - loss: 34467801.2429\n",
      "Epoch 18/500\n",
      "5130/5130 [==============================] - 0s 12us/step - loss: 34451378.1801\n",
      "Epoch 19/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 34424317.5064\n",
      "Epoch 20/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34378985.2265\n",
      "Epoch 21/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34353759.1025\n",
      "Epoch 22/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34282300.5466\n",
      "Epoch 23/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34277813.4265\n",
      "Epoch 24/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34189365.4955\n",
      "Epoch 25/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34154064.9832\n",
      "Epoch 26/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34153985.1992\n",
      "Epoch 27/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 34044121.3879\n",
      "Epoch 28/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 33976022.1684\n",
      "Epoch 29/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33899604.2152\n",
      "Epoch 30/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33843285.7809\n",
      "Epoch 31/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33793148.7454\n",
      "Epoch 32/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33728589.7029\n",
      "Epoch 33/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33647697.0635\n",
      "Epoch 34/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 33616845.3661\n",
      "Epoch 35/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 33572500.7719\n",
      "Epoch 36/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 33476286.4593\n",
      "Epoch 37/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 33429505.8823\n",
      "Epoch 38/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33342533.8698\n",
      "Epoch 39/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33270930.6729\n",
      "Epoch 40/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33195112.4959\n",
      "Epoch 41/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 33085382.7614\n",
      "Epoch 42/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 32984993.3801\n",
      "Epoch 43/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 32893492.9230\n",
      "Epoch 44/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 32755010.3743\n",
      "Epoch 45/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 32638110.1442\n",
      "Epoch 46/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 32498840.4226\n",
      "Epoch 47/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 32333936.9326\n",
      "Epoch 48/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 32207561.0277\n",
      "Epoch 49/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 32093398.6152\n",
      "Epoch 50/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 31830290.1552\n",
      "Epoch 51/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 31639565.8628\n",
      "Epoch 52/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 31392819.2491\n",
      "Epoch 53/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 31109512.3852\n",
      "Epoch 54/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 30773777.1899\n",
      "Epoch 55/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 30413689.0043\n",
      "Epoch 56/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 30126782.9240\n",
      "Epoch 57/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 29665323.6203\n",
      "Epoch 58/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 29284418.1329\n",
      "Epoch 59/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 28813274.1318\n",
      "Epoch 60/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 28364555.9641\n",
      "Epoch 61/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 27926479.6538\n",
      "Epoch 62/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 27344277.6624\n",
      "Epoch 63/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 26602697.3240\n",
      "Epoch 64/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 25889745.1782\n",
      "Epoch 65/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 25129396.3368\n",
      "Epoch 66/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 24260299.2655\n",
      "Epoch 67/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 23833848.4585\n",
      "Epoch 68/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 23155464.9840\n",
      "Epoch 69/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 22534512.1602\n",
      "Epoch 70/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 21816818.9435\n",
      "Epoch 71/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 21132092.3961\n",
      "Epoch 72/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 20206675.0612\n",
      "Epoch 73/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 19312524.7029\n",
      "Epoch 74/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 18360581.3694\n",
      "Epoch 75/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 17375999.8885\n",
      "Epoch 76/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 16325621.4269\n",
      "Epoch 77/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 15352793.2253\n",
      "Epoch 78/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 14206448.5154\n",
      "Epoch 79/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 13236393.9712\n",
      "Epoch 80/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 12406457.4043\n",
      "Epoch 81/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 10990611.5294\n",
      "Epoch 82/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 9910210.4975\n",
      "Epoch 83/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 8873242.6947\n",
      "Epoch 84/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 7840404.6129\n",
      "Epoch 85/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 7082363.3717\n",
      "Epoch 86/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 6303801.4363\n",
      "Epoch 87/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 5887223.3433\n",
      "Epoch 88/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 5248804.5755\n",
      "Epoch 89/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5130/5130 [==============================] - 0s 11us/step - loss: 4891185.1596\n",
      "Epoch 90/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 4624463.6838\n",
      "Epoch 91/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 4403382.3483\n",
      "Epoch 92/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 4333501.9416\n",
      "Epoch 93/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3930878.6495\n",
      "Epoch 94/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3904879.7515\n",
      "Epoch 95/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3766370.4471\n",
      "Epoch 96/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3740268.1108\n",
      "Epoch 97/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3699768.5815\n",
      "Epoch 98/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3689346.0625\n",
      "Epoch 99/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3662543.1788\n",
      "Epoch 100/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3579519.8879\n",
      "Epoch 101/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3564429.5283\n",
      "Epoch 102/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3524220.7385\n",
      "Epoch 103/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3626383.6008\n",
      "Epoch 104/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3565612.6350\n",
      "Epoch 105/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3572354.2712\n",
      "Epoch 106/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3514374.8135\n",
      "Epoch 107/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3515201.6278\n",
      "Epoch 108/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3471157.6026\n",
      "Epoch 109/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3444001.7349\n",
      "Epoch 110/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3435195.7415\n",
      "Epoch 111/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3550577.6984\n",
      "Epoch 112/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3387011.4330\n",
      "Epoch 113/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3389874.6710\n",
      "Epoch 114/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3363432.9435\n",
      "Epoch 115/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3520345.5513\n",
      "Epoch 116/500\n",
      "5130/5130 [==============================] - 0s 14us/step - loss: 3390122.3441\n",
      "Epoch 117/500\n",
      "5130/5130 [==============================] - 0s 13us/step - loss: 3414682.0683\n",
      "Epoch 118/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3330599.6425\n",
      "Epoch 119/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3348214.9717\n",
      "Epoch 120/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3271423.1488\n",
      "Epoch 121/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3284666.9895\n",
      "Epoch 122/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3277009.0387\n",
      "Epoch 123/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3221028.3034\n",
      "Epoch 124/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3256908.5108\n",
      "Epoch 125/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3392475.0608\n",
      "Epoch 126/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3176325.5867\n",
      "Epoch 127/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3201156.2069\n",
      "Epoch 128/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3141260.8660\n",
      "Epoch 129/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3166655.3671\n",
      "Epoch 130/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3148497.5742\n",
      "Epoch 131/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3181636.6287\n",
      "Epoch 132/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3131480.6517\n",
      "Epoch 133/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3164561.5667\n",
      "Epoch 134/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3117137.3666\n",
      "Epoch 135/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3114109.2615\n",
      "Epoch 136/500\n",
      "5130/5130 [==============================] - 0s 12us/step - loss: 3076276.0086\n",
      "Epoch 137/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3063148.6099\n",
      "Epoch 138/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3013368.8205\n",
      "Epoch 139/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 3075753.8306\n",
      "Epoch 140/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3043011.6792\n",
      "Epoch 141/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3025420.4892\n",
      "Epoch 142/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 3067688.3787\n",
      "Epoch 143/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2983063.0353\n",
      "Epoch 144/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3099154.8508\n",
      "Epoch 145/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3121048.8096\n",
      "Epoch 146/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 3069962.1447\n",
      "Epoch 147/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2964905.5588\n",
      "Epoch 148/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2960362.8870\n",
      "Epoch 149/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2952213.4828\n",
      "Epoch 150/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2904065.5499\n",
      "Epoch 151/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2934148.8604\n",
      "Epoch 152/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2965385.3396\n",
      "Epoch 153/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2938983.1904\n",
      "Epoch 154/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2868914.6599\n",
      "Epoch 155/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2856713.5060\n",
      "Epoch 156/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2874257.7878\n",
      "Epoch 157/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 2872934.9313\n",
      "Epoch 158/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2818214.0737\n",
      "Epoch 159/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2776291.8105\n",
      "Epoch 160/500\n",
      "5130/5130 [==============================] - 0s 11us/step - loss: 2758709.2103\n",
      "Epoch 161/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2894416.9041\n",
      "Epoch 162/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2830155.2171\n",
      "Epoch 163/500\n",
      "5130/5130 [==============================] - 0s 9us/step - loss: 2783050.7290\n",
      "Epoch 164/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2771348.7519\n",
      "Epoch 165/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2738886.7510\n",
      "Epoch 166/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2748710.9696\n",
      "Epoch 167/500\n",
      "5130/5130 [==============================] - 0s 10us/step - loss: 2750514.2710\n",
      "Epoch 168/500\n",
      "  64/5130 [..............................] - ETA: 0s - loss: 1214203.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0ac02219d57c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WD-Research/marcc/wdtools/neural.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, x_data, y_data, n_epochs, batchsize, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_input_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5646\u001b[0m     context.context().context_switches.push(default.building_function,\n\u001b[1;32m   5647\u001b[0m                                             \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5648\u001b[0;31m                                             default._device_function_stack)\n\u001b[0m\u001b[1;32m   5649\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5650\u001b[0m       with super(_DefaultGraphStack,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_device_function_stack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5104\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack_state_is_thread_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5106\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5107\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_device_function_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack_state_is_thread_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bnn.train(bnn.nn(),X, t, n_epochs = 500, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bounds = np.asarray([[2,52]])\n",
    "output_bounds = np.asarray([[53,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(input_bounds.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
